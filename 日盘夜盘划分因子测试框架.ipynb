{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体，或者使用你系统上可用的其他字体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用AskPrice1和BidPrice1计算价格的平均值，进而计算分钟频的收益率\n",
    "def mid_price(df):\n",
    "    mid = (df['AskPrice1'] + df['BidPrice1'])/2\n",
    "    mid = mid.astype(float)\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_factor(X):\n",
    "    X_std = (X - X.mean())/X.std()\n",
    "    return X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ic(factors, returns):\n",
    "    # 计算皮尔逊相关系数\n",
    "    ic, _ = pearsonr(factors, returns)\n",
    "    return ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数：获取前一个交易日\n",
    "def get_previous_trading_date(current_date, trading_dates):\n",
    "    idx = trading_dates.index(current_date)\n",
    "    return trading_dates[idx - 1] if idx > 0 else None\n",
    "\n",
    "def process_day(group, trading_dates):\n",
    "    \"\"\"\n",
    "    按照日盘和夜盘时间范围划分交易数据，并对每段数据进行前后切片处理，最后返回日盘和夜盘的 baskets 和 window_size。\n",
    "\n",
    "    :param group: 分组后的 DataFrame，每组是一个交易日的数据。\n",
    "    :param prev_period: 去掉每段数据前 prev_period 条记录。\n",
    "    :param back_period: 去掉每段数据后 back_period 条记录。\n",
    "    :param trading_dates: 所有交易日的序列，用于查找前一个交易日。\n",
    "    :param V: 每个桶的目标交易量（可以根据需要调整）\n",
    "    :return: 处理后的日盘和夜盘数据分别处理后的 DataFrame。\n",
    "    \"\"\"\n",
    "    # 获取当前交易日和前一个交易日\n",
    "    trading_date = group['trading_date'].iloc[0]\n",
    "    previous_trading_date = get_previous_trading_date(trading_date, trading_dates)\n",
    "\n",
    "    # 定义时间范围\n",
    "    day_start = pd.to_datetime(f\"{trading_date} 09:00:00\")\n",
    "    day_end = pd.to_datetime(f\"{trading_date} 14:57:00\")\n",
    "    night_start = pd.to_datetime(f\"{previous_trading_date} 21:00:00\") if previous_trading_date else None\n",
    "    night_end = (pd.to_datetime(f\"{previous_trading_date} 02:27:00\") + pd.Timedelta(days=1)) if previous_trading_date else None\n",
    "\n",
    "    # 筛选日盘数据\n",
    "    day_session = group[(group['exchange_time'] >= day_start) & (group['exchange_time'] <= day_end)]\n",
    "\n",
    "    # 筛选夜盘数据（需要判断是否有前一个交易日）\n",
    "    if night_start:\n",
    "        night_session = group[(group['exchange_time'] >= night_start) & (group['exchange_time'] <= night_end)]\n",
    "    else:\n",
    "        night_session = pd.DataFrame()  # 如果没有前一个交易日，则夜盘数据为空\n",
    "\n",
    "    # day_session_processed = day_session.iloc[prev_period:-back_period] \n",
    "\n",
    "    # # 如果夜盘数据存在，则进行处理；否则跳过\n",
    "    # if not night_session.empty:\n",
    "    #     night_session_processed = night_session.iloc[prev_period:-back_period]\n",
    "    # else:\n",
    "    #     night_session_processed = pd.DataFrame()  # 为空时可以直接跳过处理\n",
    "\n",
    "    # # 在日盘和夜盘数据上分别应用桶划分逻辑\n",
    "    # def bucketize_data(session_data):\n",
    "    #     # 如果 session_data 不为空并且包含 'Volume' 列\n",
    "    #     if session_data.empty or 'Volume' not in session_data.columns:\n",
    "    #         return session_data  # 返回原始数据，因为数据为空或者没有 'Volume' 列\n",
    "\n",
    "    #     # session_data['current_volume'] = session_data['Volume'].diff()\n",
    "    #     # session_data['current_volume'].fillna(0, inplace=True)\n",
    "    #     current_basket = 0  # 当前桶的交易量\n",
    "    #     window_size = 0  # 当前桶的起始索引\n",
    "\n",
    "    #     current_basket_list = []\n",
    "    #     window_size_list = []\n",
    "\n",
    "\n",
    "    #     # 遍历 `current_volume` 数据，将数据划分为多个桶\n",
    "    #     for volume in session_data['current_volume'].values:\n",
    "    #         current_basket += volume  # 累积当前桶的交易量\n",
    "    #         # current_basket_list.append(current_basket)\n",
    "    #         window_size += 1  # 增加窗口大小\n",
    "    #         # window_size_list.append(window_size)\n",
    "\n",
    "    #         # 当当前桶的交易量达到或超过目标交易量时\n",
    "    #         if current_basket >= V:\n",
    "    #             current_basket_list.extend([current_basket]*window_size)\n",
    "    #             window_size_list.extend([window_size]*window_size)\n",
    "    #             window_size = 0\n",
    "    #             current_basket = 0\n",
    "\n",
    "    #     current_basket_list.extend([current_basket]*window_size)\n",
    "    #     window_size_list.extend([window_size]*window_size)\n",
    "\n",
    "    #     session_data['basket_volume'] = current_basket_list\n",
    "    #     session_data['window_size'] = window_size_list\n",
    "\n",
    "\n",
    "    #     return session_data\n",
    "\n",
    "    # # 分别对日盘和夜盘数据进行桶划分处理\n",
    "    # day_session_processed = bucketize_data(day_session_processed)\n",
    "\n",
    "    # if not night_session_processed.empty:\n",
    "    #     night_session_processed = bucketize_data(night_session_processed)\n",
    "\n",
    "    # 拼接处理后的日盘和夜盘数据\n",
    "    # processed_data = pd.concat([night_session,day_session], ignore_index=True)\n",
    "\n",
    "    # 返回处理后的日盘和夜盘数据\n",
    "    return night_session,day_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = pd.read_parquet(r\"C:\\Ter\\source\\sp\")\n",
    "# table['trading_date'] = pd.to_datetime(table['trading_date']) \n",
    "\n",
    "# # 设置开始和结束时间\n",
    "# start_time = pd.to_datetime('2023-07-01')\n",
    "# end_time = pd.to_datetime('2024-06-30')\n",
    "\n",
    "# table = table[(table['trading_date'] >= start_time) & (table['trading_date'] <= end_time)]\n",
    "\n",
    "# # 当 AskPrice1 为 0 时，用 BidPrice1 替换\n",
    "# table['AskPrice1'] = table['AskPrice1'].where(table['AskPrice1'] != 0, table['BidPrice1'])\n",
    "\n",
    "# # 当 AskPrice1 为 0 时，用 AskPrice1 替换\n",
    "# table['BidPrice1'] = table['BidPrice1'].where(table['BidPrice1'] != 0, table['AskPrice1'])\n",
    "\n",
    "# # 计算一些差分数据\n",
    "# table['current_volume'] = table['Volume'].diff()\n",
    "# table['Position Increase'] = table['OpenInterest'].diff()\n",
    "# table['current_turnover'] = table['Turnover'].diff()\n",
    "# table['current_avg_price'] = table['current_turnover']/(table['current_volume']*10)\n",
    "# table['mid_price'] = mid_price(table)\n",
    "# table['current_volume'].fillna(0,inplace=True)\n",
    "# table['return'] = -mid_price(table).diff(-120)\n",
    "# table['return'].fillna(0,inplace=True)\n",
    "\n",
    "# table['buy_sell_signal'] = 0\n",
    "# table.loc[table['last'] >= table['AskPrice1'].shift(1),'buy_sell_signal'] = 1\n",
    "# table.loc[table['last'] <= table['BidPrice1'].shift(1),'buy_sell_signal'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'ag'\n",
    "df = pd.read_parquet(fr\"C:\\Ter\\source\\{symbol}\")\n",
    "df['trading_date'] = pd.to_datetime(df['trading_date']) \n",
    "# 设置开始和结束时间\n",
    "start_time = pd.to_datetime('2023-07-01')\n",
    "end_time = pd.to_datetime('2024-06-30')\n",
    "\n",
    "table = df[(df['trading_date'] >= start_time) & (df['trading_date'] <= end_time)]\n",
    "\n",
    "# 当 AskPrice1 为 0 时，用 BidPrice1 替换\n",
    "table['AskPrice1'] = table['AskPrice1'].where(table['AskPrice1'] != 0, table['BidPrice1'])\n",
    "\n",
    "# 当 AskPrice1 为 0 时，用 AskPrice1 替换\n",
    "table['BidPrice1'] = table['BidPrice1'].where(table['BidPrice1'] != 0, table['AskPrice1'])\n",
    "\n",
    "# 计算一些基本信息\n",
    "table['mid_price'] = (table['BidPrice1'] + table['AskPrice1']) / 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按 'trading_date' 分组，使用 process_day 处理每个分组\n",
    "# new_table = table[~table['trading_date'].isin([pd.to_datetime('2023-12-08')])].reset_index(drop=True)\n",
    "new_table = table.copy()\n",
    "# new_table = table[~table['trading_date'].isin([pd.to_datetime('2024-04-08'),pd.to_datetime('2024-05-20')])]\n",
    "unique_trading_dates = sorted(new_table['trading_date'].unique())\n",
    "result = new_table.groupby('trading_date').apply(process_day,trading_dates=unique_trading_dates)\n",
    "# 处理结果：返回每一天的日盘和夜盘数据以及合并后的结果\n",
    "concat_results = []\n",
    "day_results = []\n",
    "night_results = []\n",
    "\n",
    "from factor_install import *\n",
    "\n",
    "\n",
    "for night_df,day_df in result:\n",
    "    day_df['frt_120'] = -day_df['mid_price'].diff(-120)\n",
    "    day_df['frt_120'].fillna(0,inplace=True)\n",
    "    factor_install(day_df,symbol)\n",
    "    if not night_df.empty:\n",
    "        night_df['frt_120'] = -night_df['mid_price'].diff(-120)\n",
    "        night_df['frt_120'].fillna(0,inplace=True)\n",
    "        factor_install(night_df,symbol)\n",
    "\n",
    "    concat_df = pd.concat([night_df,day_df],ignore_index=True)\n",
    "    # day_results.append(day_df)\n",
    "    # night_results.append(night_df)\n",
    "    concat_results.append(concat_df)\n",
    "\n",
    "# day_data = pd.concat(day_results,ignore_index=True)\n",
    "# night_data = pd.concat(night_results,ignore_index=True)\n",
    "train_data = pd.concat(concat_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_columns = ['Base_factor','BAV_diff_transform','pending_vol_ratio_factor', 'submit_price_imbalance', 'relative_vol_ratio_imbalance']\n",
    "new_factor_columns = []\n",
    "for i in factor_columns:\n",
    "    new_factor_columns.extend([col for col in train_data.columns if (i+'_lag') in col])\n",
    "    \n",
    "# mean = train_data[factor_columns].mean().to_numpy().flatten().tolist()\n",
    "# std = train_data[factor_columns].std().to_numpy().flatten().tolist()\n",
    "\n",
    "# # 保留小数点后 6 位\n",
    "# mean = [round(num, 6) for num in mean]\n",
    "# std = [round(num, 6) for num in std]\n",
    "\n",
    "# print(f'均值为：{mean}')\n",
    "# print(f'标准差为:{std}')\n",
    "\n",
    "# train_data[factor_columns] = (train_data[factor_columns] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "x = train_data[new_factor_columns].to_numpy()\n",
    "y = train_data['frt_120'].to_numpy()\n",
    "\n",
    "# 将 x 和 y 转换为 torch.Tensor 类型\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# 定义线性回归模型，输入维度为 35，输出维度为 1，不使用偏置项\n",
    "model = nn.Linear(30, 1, bias=False)\n",
    "\n",
    "# 自定义 Cauchy 负对数似然损失函数\n",
    "def cauchy_loss(outputs, targets):\n",
    "    residuals = targets - outputs\n",
    "    return torch.mean(torch.log(1 + (residuals ** 2)))\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 1000\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):\n",
    "    # 前向传播\n",
    "    outputs = model(x)\n",
    "    loss = cauchy_loss(outputs, y)\n",
    "\n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 由于有 35 个特征，无法直接绘制 35 维的拟合图，这里可以简单查看预测值和真实值的差异\n",
    "predicted = model(x).detach().numpy()\n",
    "print(\"真实值前几个样本：\", y[:5].numpy().flatten())\n",
    "print(\"预测值前几个样本：\", predicted[:5].flatten())\n",
    "\n",
    "# 获取并打印线性系数的值\n",
    "linear_coefficients = model.weight.detach().numpy().flatten()\n",
    "print(\"线性系数的值：\", linear_coefficients)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = linear_coefficients.tolist()\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# batch_size = 10240\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# x = train_data[new_factor_columns].to_numpy()\n",
    "# y = train_data['frt_120'].to_numpy()\n",
    "\n",
    "# # 将 x 和 y 转换为 torch.Tensor 类型\n",
    "# x = torch.tensor(x, dtype=torch.float32)\n",
    "# y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# dataset = TensorDataset(x, y)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # 定义线性回归模型，输入维度为 35，输出维度为 1，不使用偏置项\n",
    "# model = nn.Linear(30, 1)\n",
    "# mode = model.to(device)\n",
    "# model.train()\n",
    "\n",
    "# # 自定义 Cauchy 负对数似然损失函数\n",
    "# def cauchy_loss(outputs, targets):\n",
    "#     residuals = targets - outputs\n",
    "#     return torch.mean(torch.log(1 + (residuals ** 2)))\n",
    "\n",
    "# def some_loss(outputs, targets):\n",
    "#     return torch.mean(torch.abs((outputs-targets)*targets))\n",
    "\n",
    "# criterion = some_loss\n",
    "\n",
    "# # 定义优化器\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "# print(device)\n",
    "\n",
    "# # 训练模型\n",
    "# num_epochs = 1000\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     for batch_x, batch_y in dataloader:\n",
    "#         batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "#         # 前向传播\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_x)\n",
    "#         loss = criterion(outputs, batch_y)\n",
    "\n",
    "#         # 反向传播和优化\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#     print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}')\n",
    "\n",
    "# # 由于有 35 个特征，无法直接绘制 35 维的拟合图，这里可以简单查看预测值和真实值的差异\n",
    "# predicted = model(x).detach().numpy()\n",
    "# print(\"真实值前几个样本：\", y[:5].numpy().flatten())\n",
    "# print(\"预测值前几个样本：\", predicted[:5].flatten())\n",
    "\n",
    "# # 获取并打印线性系数的值\n",
    "# linear_coefficients = model.weight.detach().numpy().flatten()\n",
    "# print(\"线性系数的值：\", linear_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.optimize import minimize\n",
    "\n",
    "# # 提取因子和目标变量\n",
    "# X = train_data[new_factor_columns].to_numpy()\n",
    "# y = train_data['frt_120'].to_numpy()\n",
    "\n",
    "# # Cauchy负对数似然函数\n",
    "# def cauchy_loss(params, X, y):\n",
    "#     y_pred = np.dot(X, params)\n",
    "#     residuals = y - y_pred\n",
    "#     return np.sum(np.log(1 + (residuals ** 2)))\n",
    "\n",
    "# # 初始参数（全为0）\n",
    "# initial_params = np.zeros(X.shape[1])\n",
    "\n",
    "# # 极大似然估计\n",
    "# result = minimize(cauchy_loss, initial_params, args=(X, y))\n",
    "\n",
    "# # 回归系数\n",
    "# coefficients = pd.DataFrame(result.x, index=new_factor_columns, columns=['Coefficient']).to_numpy().flatten().tolist()\n",
    "# coefficients = [round(num, 6) for num in coefficients]\n",
    "\n",
    "# print(coefficients)\n",
    "\n",
    "# # 计算因子值\n",
    "# train_data['factor'] = np.dot(X, result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data['segment'] = (final_data['window_size'] != final_data['window_size'].shift()).cumsum()\n",
    "\n",
    "# # 计算每段的统计特征（例如均值、标准差、最大值等）\n",
    "# current_volume_stats = final_data.groupby('segment')['current_volume'].agg(\n",
    "#     current_volume_mean='mean',\n",
    "#     current_volume_std='std',\n",
    "#     current_volume_min='min',\n",
    "#     current_volume_max='max',\n",
    "#     current_volume_count='count'\n",
    "# ).reset_index()\n",
    "# return_stats = final_data.groupby('segment')['return'].agg(\n",
    "#     return_mean='mean',\n",
    "#     return_std='std',\n",
    "#     return_min='min',\n",
    "#     return_max='max',\n",
    "#     return_count='count'\n",
    "# ).reset_index()\n",
    "\n",
    "# # 将每个段的统计特征加入原始数据\n",
    "# final_data = final_data.merge(current_volume_stats, on='segment', how='left')\n",
    "# final_data = final_data.merge(return_stats, on='segment', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = final_data.groupby(final_data['segment'])\n",
    "# max_volume_rows = grouped.apply(lambda x: x.loc[x['current_volume'].idxmax()])\n",
    "# def calculate_sign(group):\n",
    "#     # 找到 current_volume 最大的行\n",
    "#     max_row = group.loc[group['current_volume'].idxmax()]\n",
    "    \n",
    "#     # 获取该行的 current_avg_price, AskPrice1 和 BidPrice1 的值\n",
    "#     current_avg_price = max_row['current_avg_price']\n",
    "#     AskPrice1_prev = group['AskPrice1'].shift(1)\n",
    "#     BidPrice1_prev = group['BidPrice1'].shift(1)\n",
    "    \n",
    "#     # 计算 sign 值\n",
    "#     sign_value = np.sign(2 * current_avg_price - AskPrice1_prev - BidPrice1_prev)\n",
    "    \n",
    "#     # 将 sign 值赋给当前组的所有行\n",
    "#     group['sign'] = sign_value\n",
    "#     group['sign'].fillna(method='bfill', inplace=True)\n",
    "#     return group\n",
    "\n",
    "# final_data = final_data.groupby('segment').apply(calculate_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = final_data.groupby(final_data['segment'])\n",
    "# max_volume_rows = grouped.apply(lambda x: x.loc[x['current_volume'].idxmax()])\n",
    "# def calculate_sign(group):\n",
    "#     # 找到 current_volume 最大的行\n",
    "#     max_row = group.loc[group['current_volume'].idxmax()]\n",
    "#     # 计算 sign 值\n",
    "#     factor_value = max_row['buy_sell_signal']\n",
    "#     # 将 sign 值赋给当前组的所有行\n",
    "#     group['factor'] = factor_value\n",
    "#     group['factor'].fillna(method='bfill', inplace=True)\n",
    "#     return group\n",
    "\n",
    "# df = final_data.groupby('segment').apply(calculate_sign)\n",
    "# df.rename(columns={'segment':'segment_columns'},inplace=True)\n",
    "# last_rows = df.groupby('segment').tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_rows[['factor','return']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data['factor'] = final_data['sign'] * final_data['current_volume']\n",
    "# final_data[['factor','return']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_volume_rows['sign'] = np.sign(2*max_volume_rows['current_avg_price']-max_volume_rows['AskPrice1']-max_volume_rows['BidPrice1'])\n",
    "# max_volume_rows['factor'] = max_volume_rows['sign']*max_volume_rows['current_volume']\n",
    "# max_volume_rows[['factor','return']].corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
